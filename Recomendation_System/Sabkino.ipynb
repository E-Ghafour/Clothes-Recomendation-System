{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "72f4fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83d82205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n equal to number of features\n",
    "n = 5\n",
    "\n",
    "# m equal to number of samples\n",
    "m = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72f4fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a855af",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0254f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self, path='accounts_style.csv' ):\n",
    "        self.path = path\n",
    "        self.data = self.__preprecessing(path)\n",
    "        self.data = self.__normalize_based_on_values([2, 2, 1.5, 1.25, 1.75])\n",
    "\n",
    "    \n",
    "    def getData(self):\n",
    "        return self.data\n",
    "\n",
    "\n",
    "    def fit_predict(self, n_clusters=6):\n",
    "        kmeans = KMeans(n_clusters = n_clusters, init = 'k-means++', random_state = 42)\n",
    "        self.kmeans = kmeans\n",
    "        return kmeans.fit_predict(self.data)\n",
    "\n",
    "    \n",
    "    def cluster_centers(self):\n",
    "        return self.kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "    def predict(self, input):\n",
    "        return self.kmeans.predict(input)\n",
    "\n",
    "    \n",
    "    def __preprecessing(self, path):\n",
    "        #select special part of the dataframe\n",
    "        data = pd.read_csv(path)\n",
    "        data = data.iloc[ : ,2:]\n",
    "\n",
    "        #spilit data and add new culomns\n",
    "        data[['Age1', 'Age2', 'Age3']] = data[\"Age\"].str.split(\",\", n=2, expand=True)\n",
    "        data[['Color1', 'Color2', 'Color3']] = data[\"Color\"].str.split(\",\", n=2, expand=True)\n",
    "        data[['Pattern1', 'Pattern2', 'Pattern3']] = data[\"Pattern\"].str.split(\",\", n=2, expand=True)\n",
    "        data[['Size1', 'Size2', 'Size3']] = data[\"Size\"].str.split(\",\", n=2, expand=True)\n",
    "        data[['Formal1', 'Formal2', 'Formal3']] = data[\"Formal\"].str.split(\",\", n=2, expand=True)\n",
    "\n",
    "        #drop unusage columns\n",
    "        data.drop(columns =['Age', 'Color', 'Pattern', 'Size', 'Formal'], inplace = True)\n",
    "\n",
    "        #convert type from str to float64\n",
    "        data = data.astype('float64')\n",
    "\n",
    "        #calculate the average of each row specialy\n",
    "        data['Age_avg'] = self.__special_mean(data[['Age1', 'Age2', 'Age3']].values,20)\n",
    "        data['Color-avg'] = self.__special_mean(data[['Color1', 'Color2', 'Color3']].values,20)\n",
    "        data['Pattern_avg'] = self.__special_mean(data[['Pattern1', 'Pattern2', 'Pattern3']].values,20)\n",
    "        data['Size-avg'] = self.__special_mean(data[['Size1', 'Size2', 'Size3']].values,20)\n",
    "        data['Formal_avg'] = self.__special_mean(data[['Formal1', 'Formal2', 'Formal3']].values,20)\n",
    "\n",
    "        #drop unusage columns\n",
    "        data.drop(columns =['Age1', 'Age2', 'Age3', 'Color1', 'Color2', 'Color3', 'Pattern1',\n",
    "         'Pattern2', 'Pattern3', 'Size1', 'Size2', 'Size3', 'Formal1', 'Formal2', 'Formal3'], inplace = True)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "    def __normalize_based_on_values(self, values):\n",
    "        #normalize data from 0 to 1\n",
    "        normalized_data = pd.DataFrame(preprocessing.normalize(self.data), columns=self.data.columns)\n",
    "\n",
    "        #put it in -1 to +1\n",
    "        normalized_data = (normalized_data - 0.5) * 2\n",
    "\n",
    "        #change the period for each component to change the influence\n",
    "        normalized_data = normalized_data * values\n",
    "        return normalized_data\n",
    "\n",
    "\n",
    "    def __special_mean(self, selectedClothes, anomaly):\n",
    "        # we have to ignore anomaly values in each component to have accessed the real mean value\n",
    "        meanVector = []\n",
    "        for i in range(np.shape(selectedClothes)[0]):\n",
    "            componentSum = 0\n",
    "            count = 0\n",
    "            for j in range(np.shape(selectedClothes)[1]):\n",
    "                if(selectedClothes[i][j] != anomaly):\n",
    "                    componentSum += selectedClothes[i][j]\n",
    "                    count += 1\n",
    "            meanVector.append(componentSum/count)\n",
    "\n",
    "        return meanVector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8b2b0f",
   "metadata": {},
   "source": [
    "## recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6a50e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationSystem:\n",
    "    \n",
    "    def __init__(self, allClothes):\n",
    "        self.allClothes = allClothes\n",
    "        self.clustering = Clustering(path='accounts_style.csv')\n",
    "        self.answers = self.clustering.fit_predict(n_clusters=6)\n",
    "        self.preparedData = self.clustering.getData()\n",
    "        self.preparedDataWithAnswers = self.preparedData\n",
    "        self.preparedDataWithAnswers['Answers'] = self.answers\n",
    "\n",
    "        \n",
    "    def get_prepared_data(self):\n",
    "        return self.preparedData\n",
    "\n",
    "    def get_prepared_data_with_anwers(self):\n",
    "        return self.preparedDataWithAnswers\n",
    "\n",
    "    def recommend_based_on_questions(self, values, customer_feature1, customer_feature2, customer_feature3, customer_feature4, k1 = 4, k2=1, k3=1, k4=1):\n",
    "    \n",
    "        #k nearest neighbor\n",
    "        k_indices1 = self.__one_recommend(customer_feature1, values, k1)\n",
    "        k_indices2 = self.__one_recommend(customer_feature2, values, k2)\n",
    "        k_indices3 = self.__one_recommend(customer_feature3, values, k3)\n",
    "        k_indices4 = self.__one_recommend(customer_feature4, values, k4)\n",
    "                \n",
    "        # merge and unigue indices(union)\n",
    "        k_indices = np.append(k_indices1, np.append(k_indices2, np.append(k_indices3, k_indices4)))\n",
    "        \n",
    "        # return the selected style indices \n",
    "        return k_indices\n",
    "\n",
    "\n",
    "    def recommend_based_on_clothes(self, selectedClothes, values, anomaly = 20, k=5):\n",
    "        \n",
    "        #asume average of the each component for the as the customer vector of self.__oneRecommend little diffrent with the ordinary averages\n",
    "        average_of_multi_tags = self.__special_mean(selectedClothes, anomaly)\n",
    "        k_indeces = self.__one_recommend(average_of_multi_tags, values, k)\n",
    "        return k_indeces\n",
    "\n",
    "\n",
    "    def recommend_based_on_cluster(self, cluster_taste, k=30):\n",
    "        \n",
    "        return 1\n",
    "\n",
    "\n",
    "    def __one_recommend(self, customer, values, k):\n",
    "        # compute distances by one of the distance(distance_1, distance_2, ...) functions\n",
    "        distances = np.array([self.__similarity2(customer, f, values) for f in self.allClothes])\n",
    "        \n",
    "        # return k nearest style indices\n",
    "        return np.argsort(distances)[: k]\n",
    "\n",
    "\n",
    "\n",
    "    def update_cluster_taste(self, prev_cluster_taste, comment, clothesInd, alpha = 0.1 ):\n",
    "        #find the class number of clothes\n",
    "        #clusterNumber = self.which_cluster(clothesInd)\n",
    "        clusterNumber = 3\n",
    "        \n",
    "        #calculate the new replacement for selected cluster with weighted average\n",
    "        weightedAverage = np.average([prev_cluster_taste[clusterNumber], comment], weights=[1,alpha])\n",
    "\n",
    "        #update prev_Cluster_taste \n",
    "        prev_cluster_taste[clusterNumber] = weightedAverage\n",
    "        return prev_cluster_taste\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.preparedData\n",
    "\n",
    "    def __clustring(self, clothes):\n",
    "        return 1\n",
    "\n",
    "        \n",
    "    def which_cluster(ClothesInd):\n",
    "        return 1\n",
    "\n",
    "\n",
    "    def __similarity1(self, customer, clothes, values):\n",
    "        lowestMines = self.__lowest_mines(customer, clothes)      \n",
    "        return np.sum(values * np.abs(lowestMines))\n",
    "    \n",
    "    \n",
    "    def __similarity2(self, customer, clothes, values):\n",
    "        lowestMines = self.__lowest_mines(customer, clothes)      \n",
    "        return np.sqrt(np.sum(values*((lowestMines) ** 2 )))\n",
    "\n",
    "\n",
    "    def __lowest_mines(self, customer, clothes):\n",
    "        bestClothes = []\n",
    "        tmpArray1 = []\n",
    "        for i in range(len(customer)):\n",
    "            for j in range(np.shape(clothes)[1]):\n",
    "                tmpArray1.append(abs((customer[i] - clothes[i][j])))\n",
    "            bestClothes.append(min(tmpArray1))  \n",
    "            tmpArray1 = []\n",
    "        return np.array(bestClothes)\n",
    "\n",
    "    def __special_mean(self, selectedClothes, anomaly):\n",
    "        # we have to ignore anomaly values in each component to have access the real mean value\n",
    "        meanVector = []\n",
    "        for i in range(np.shape(selectedClothes)[0]):\n",
    "            componentSum = 0\n",
    "            count = 0\n",
    "            for j in range(np.shape(selectedClothes)[1]):\n",
    "                if(selectedClothes[i][j] != anomaly):\n",
    "                    componentSum += selectedClothes[i][j]\n",
    "                    count += 1\n",
    "            meanVector.append(componentSum/count)\n",
    "\n",
    "        return meanVector\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    def extract_clothes(self, clothes):\n",
    "        return 1\n",
    "\n",
    "\n",
    "    def remove_duplicates(self, clothes):\n",
    "        return 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ea097",
   "metadata": {},
   "source": [
    "### 1.Test of recommend_based_on_questions function \n",
    "---\n",
    "creating random data and check the answers of recommend_based_on_questions function, subfunctions.\n",
    "its subfuctions including:\n",
    "- __similarity2\n",
    "- __lowest_mines\n",
    "- __one_recommend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22d324bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2a8a5bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 3.]\n",
      "  [4. 0. 2.]\n",
      "  [2. 3. 4.]\n",
      "  [3. 2. 1.]\n",
      "  [0. 2. 1.]]\n",
      "\n",
      " [[0. 3. 2.]\n",
      "  [3. 1. 3.]\n",
      "  [3. 0. 3.]\n",
      "  [4. 2. 1.]\n",
      "  [4. 1. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "#create random clothes tags\n",
    "my_list = [0, 1, 2, 3, 4]\n",
    "clothes = np.zeros((m, n, 3))\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        for k in range(3):\n",
    "            clothes[i, j, k] = random.choice(my_list)\n",
    "    \n",
    "print(clothes[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8634945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 3 1 2] [4 3 1 1 2] [4 4 2 1 3] [1 4 4 2 3]\n"
     ]
    }
   ],
   "source": [
    "#create random personal tags\n",
    "customer1 = np.array([random.choice(my_list) for j in range(n)])\n",
    "\n",
    "#create 3 random selected style tags\n",
    "customer2 = np.array([random.choice(my_list) for j in range(n)])\n",
    "customer3 = np.array([random.choice(my_list) for j in range(n)])\n",
    "customer4 = np.array([random.choice(my_list) for j in range(n)])\n",
    "print(customer1, customer2, customer3, customer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "67713401",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendationSystem = RecommendationSystem(clothes)\n",
    "\n",
    "distances_indices = recommendationSystem.recommend_based_on_questions([1,1,1,1,1], customer1, customer2, customer3, customer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4810e76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 3 1 2]\n",
      "[[[4. 3. 1.]\n",
      "  [1. 1. 4.]\n",
      "  [3. 4. 0.]\n",
      "  [1. 3. 0.]\n",
      "  [3. 3. 2.]]\n",
      "\n",
      " [[1. 4. 2.]\n",
      "  [2. 1. 4.]\n",
      "  [2. 3. 0.]\n",
      "  [0. 2. 1.]\n",
      "  [2. 0. 0.]]\n",
      "\n",
      " [[3. 4. 2.]\n",
      "  [1. 1. 2.]\n",
      "  [4. 4. 2.]\n",
      "  [1. 0. 4.]\n",
      "  [3. 2. 2.]]\n",
      "\n",
      " [[4. 3. 2.]\n",
      "  [4. 2. 3.]\n",
      "  [4. 3. 2.]\n",
      "  [2. 1. 3.]\n",
      "  [3. 3. 2.]]\n",
      "\n",
      " [[4. 1. 3.]\n",
      "  [3. 2. 4.]\n",
      "  [0. 2. 1.]\n",
      "  [1. 4. 2.]\n",
      "  [0. 0. 2.]]\n",
      "\n",
      " [[4. 3. 2.]\n",
      "  [4. 2. 3.]\n",
      "  [4. 3. 2.]\n",
      "  [2. 1. 3.]\n",
      "  [3. 3. 2.]]\n",
      "\n",
      " [[4. 1. 3.]\n",
      "  [1. 4. 1.]\n",
      "  [3. 0. 4.]\n",
      "  [4. 4. 2.]\n",
      "  [4. 3. 1.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(customer1)\n",
    "print(clothes[distances_indices])\n",
    "type(distances_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d039c8",
   "metadata": {},
   "source": [
    "### 2.Test of update_cluster_taste function \n",
    "---\n",
    "creating random data and check the answers of update_cluster_taste function, subfunctions.\n",
    "its subfuctions including:\n",
    "- __which_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "31dfb83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 4.636363636363636, 5]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__wich_cluster always return 1 untill clustering implementation\n",
    "clusterTaste = [5, 5, 5, 5, 5]\n",
    "recommendationSystem.update_cluster_taste(prev_cluster_taste=clusterTaste, comment=1, clothesInd=145)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf19dc",
   "metadata": {},
   "source": [
    "### 3.Test of recommend_based_on_clothes function \n",
    "---\n",
    "creating random data and check the answers of recommend_based_on_clothes function, subfunctions.\n",
    "its subfuctions including:\n",
    "- __special_mean\n",
    "- __one_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f0a15c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 2., 1.],\n",
       "        [1., 3., 3.],\n",
       "        [1., 1., 4.],\n",
       "        [0., 1., 2.],\n",
       "        [1., 3., 4.]],\n",
       "\n",
       "       [[4., 2., 0.],\n",
       "        [3., 1., 4.],\n",
       "        [3., 2., 4.],\n",
       "        [0., 0., 2.],\n",
       "        [0., 0., 3.]],\n",
       "\n",
       "       [[2., 0., 3.],\n",
       "        [1., 1., 3.],\n",
       "        [1., 3., 4.],\n",
       "        [3., 1., 2.],\n",
       "        [0., 3., 2.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [1., 0., 2.],\n",
       "        [3., 2., 4.],\n",
       "        [2., 3., 0.],\n",
       "        [3., 2., 3.]],\n",
       "\n",
       "       [[3., 2., 2.],\n",
       "        [1., 3., 2.],\n",
       "        [3., 3., 2.],\n",
       "        [0., 0., 2.],\n",
       "        [2., 3., 3.]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothesTest = [[1,2,10], [1,10,10], [3,4,10], [1,2,3], [2,3,4]]\n",
    "indecesTest3 = recommendationSystem.recommend_based_on_clothes(clothesTest, values=[1,1,1,1,1], anomaly=10 )\n",
    "clothes[indecesTest3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "33a2ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparedData = recommendationSystem.get_prepared_data_with_anwers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cfd5bbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_avg</th>\n",
       "      <th>Color-avg</th>\n",
       "      <th>Pattern_avg</th>\n",
       "      <th>Size-avg</th>\n",
       "      <th>Formal_avg</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.351673</td>\n",
       "      <td>0.747211</td>\n",
       "      <td>-1.087918</td>\n",
       "      <td>-0.219796</td>\n",
       "      <td>-0.307714</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.045289</td>\n",
       "      <td>0.443389</td>\n",
       "      <td>-1.133492</td>\n",
       "      <td>-0.333729</td>\n",
       "      <td>-0.039628</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.845299</td>\n",
       "      <td>0.886751</td>\n",
       "      <td>-1.066987</td>\n",
       "      <td>-0.167468</td>\n",
       "      <td>-0.234456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.780011</td>\n",
       "      <td>1.049971</td>\n",
       "      <td>-1.042504</td>\n",
       "      <td>-0.487507</td>\n",
       "      <td>-0.148765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.718975</td>\n",
       "      <td>0.562050</td>\n",
       "      <td>-1.019616</td>\n",
       "      <td>-0.049039</td>\n",
       "      <td>-0.068654</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-0.166603</td>\n",
       "      <td>-0.166603</td>\n",
       "      <td>-0.949981</td>\n",
       "      <td>-0.333302</td>\n",
       "      <td>0.495911</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-0.592805</td>\n",
       "      <td>0.814390</td>\n",
       "      <td>-0.233524</td>\n",
       "      <td>-0.546402</td>\n",
       "      <td>-0.518704</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-0.492443</td>\n",
       "      <td>0.713602</td>\n",
       "      <td>-0.143199</td>\n",
       "      <td>-0.307777</td>\n",
       "      <td>-0.958533</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>-0.158851</td>\n",
       "      <td>-0.158851</td>\n",
       "      <td>0.157034</td>\n",
       "      <td>-0.329425</td>\n",
       "      <td>-0.461196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>-0.623143</td>\n",
       "      <td>0.753714</td>\n",
       "      <td>-0.260829</td>\n",
       "      <td>-0.389465</td>\n",
       "      <td>-0.545250</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age_avg  Color-avg  Pattern_avg  Size-avg  Formal_avg  Answers\n",
       "0   -0.351673   0.747211    -1.087918 -0.219796   -0.307714        4\n",
       "1   -0.045289   0.443389    -1.133492 -0.333729   -0.039628        4\n",
       "2   -0.845299   0.886751    -1.066987 -0.167468   -0.234456        0\n",
       "3   -0.780011   1.049971    -1.042504 -0.487507   -0.148765        0\n",
       "4   -0.718975   0.562050    -1.019616 -0.049039   -0.068654        4\n",
       "..        ...        ...          ...       ...         ...      ...\n",
       "395 -0.166603  -0.166603    -0.949981 -0.333302    0.495911        4\n",
       "396 -0.592805   0.814390    -0.233524 -0.546402   -0.518704        5\n",
       "397 -0.492443   0.713602    -0.143199 -0.307777   -0.958533        5\n",
       "398 -0.158851  -0.158851     0.157034 -0.329425   -0.461196        2\n",
       "399 -0.623143   0.753714    -0.260829 -0.389465   -0.545250        5\n",
       "\n",
       "[400 rows x 6 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preparedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e86a97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52d90d3cc821dd0beedd6e719dbdecc722c226b9d90ed1b663c34e1877f1142e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
